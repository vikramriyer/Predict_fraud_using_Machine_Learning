# Identifying Fraud in Enron Emails

## Summary

### Aim
Given emails of a person, being able to predict if the person is person of interest (poi).

### Dataset
The Enron email dataset contains approximately 500,000 emails generated by employees of the Enron Corporation. It was obtained by the Federal Energy Regulatory Commission during its investigation of Enron's collapse.

### Why machine learning?
There are almost 5,00,000 emails that have been shared across the organization. There must be a lot of things that we have to check to make sure that a person is 'poi'. Right from finding out each and every feature to the relations between each of them to drawing insights about who might be a poi, everything can be done in a easy and better way if machine learning algorithms are used. Mining the dataset manually would consume a lot of time and effort.

### Outliers
- NaN: The dataset had some outliers that had to be cleant so as to make the analysis easier and the algorithms robust. Some of the features were high in NaN values, which made no sense and was pure noise. Thus these were removed. The threashold I set was if more than 50% are NaN, discard the feature. On the same lines, some data points had all of the values set to NaN; these were removed too.
- TOTAL: This must have been a spreadsheet calculation. The value is the sum of all the total_payments, hence a lot larger and had to be removed. We can calculate the values anytime we want with inbuilt functions. This one was removed as well.

## Feature Engineering

### I engineered 3 features totally.
1. fraction of messages from poi
2. fraction of messages to poi
The above would ensure that the emails were scaled properly which makes the data easy to understand. 
For ex: If height(cm) and weights(kg) of people are to be plotted on a graph, and both the features are not scaled, it would
seem like the axis where height is plotted is longer, and thus, predictions would be biased towards considering height. However, better is that we scale both the features because the weight too plays a significant role in knowing about a person.

3. total_assets
This feature was more of intuitive and interesting one. It is important to know who made the most money considering all the financial features present in the dataset. Added up 'salary', 'total_stock_value', 'exercised_stock_options' and 'bonus'

## Algorithms
Initially I used 3 algorithms, by splitting the data into training and testing sets using the train_test_split function.
The 3 algorithms were:
knn, svm and decision trees.

Since the dataset is smaller, it is generally better if we can do a k-fold cross_validation so that there are different types of training and testing data sets and value is computed on their mean(s).

For tuning the Decision tree classifier I mentioned the below parameters:
max_depth=11, random_state=51

## Validation and Evaluation
Initially when I was trying with almost all the classifiers I could, I got an accuracy of above 90%. However, the precision and recall were as low as 0.0 which was bothersome.
After tuning the parameters, the recall and precision crossed the 30% threshold mark. This can be done better and will do it in the next iterations as I dig more into tuning of the algorithm and evaluation.

The benchmarks are as follows:
Accuracy: 83%
Precision: 31%
Recall: 35%

In mathematical terms, 
precision = tp / (tp + fp)
recall = tp / (tp + fn)
where tp = true positive
fp = false positive
fn = false negative

## References
https://docs.google.com/document/d/12-vI18qm2R79xpjmwloy-lKe5GdHV_KQVpaweieOnXY/edit?usp=sharing
http://scikit-learn.org/stable/modules/pipeline.html
http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html
http://chrisstrelioff.ws/sandbox/2015/06/25/decision_trees_in_python_again_cross_validation.html
http://dataaspirant.com/2017/02/01/decision-tree-algorithm-python-with-scikit-learn/
http://machinelearningmastery.com/tune-number-size-decision-trees-xgboost-python/
https://discussions.udacity.com/t/selectkbest-best-value-for-k/235319/1
https://docs.google.com/document/d/12-vI18qm2R79xpjmwloy-lKe5GdHV_KQVpaweieOnXY/edit#
https://www.quora.com/What-is-the-best-way-to-understand-the-terms-precision-and-recall
